\babel@toc {ngerman}{}
\contentsline {chapter}{Inhaltsverzeichnis}{II}{chapter*.3}%
\contentsline {chapter}{Abbildungsverzeichnis}{III}{chapter*.4}%
\contentsline {chapter}{Tabellenverzeichnis}{IV}{chapter*.9}%
\contentsline {chapter}{Abkürzungsverzeichnis}{V}{chapter*.10}%
\contentsline {chapter}{Quellcodeverzeichnis}{VI}{chapter*.11}%
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.12}%
\contentsline {section}{\numberline {1.1}Zielsetzung}{2}{section.16}%
\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{3}{section.18}%
\contentsline {section}{\numberline {1.3}Forschungsstand \& Referenzen}{3}{section.20}%
\contentsline {chapter}{\numberline {2}Deep Learning}{5}{chapter.25}%
\contentsline {section}{\numberline {2.1}Neuronale Netze}{5}{section.27}%
\contentsline {section}{\numberline {2.2}Architekturen}{7}{section.32}%
\contentsline {subsection}{\numberline {2.2.1}Recurrent Neural Networks}{7}{subsection.33}%
\contentsline {subsection}{\numberline {2.2.2}Encoder-Decoder-Networks}{10}{subsection.37}%
\contentsline {subsection}{\numberline {2.2.3}Attention in Neural Networks}{12}{subsection.39}%
\contentsline {subsection}{\numberline {2.2.4}Transformer Networks}{14}{subsection.44}%
\contentsline {section}{\numberline {2.3}Hyperparameter}{16}{section.46}%
\contentsline {section}{\numberline {2.4}Transfer Learning}{18}{section.51}%
\contentsline {chapter}{\numberline {3}Natural Language Processing}{20}{chapter.53}%
\contentsline {section}{\numberline {3.1}Vorverarbeitung}{21}{section.56}%
\contentsline {subsection}{\numberline {3.1.1}Textbereinigung}{21}{subsection.57}%
\contentsline {subsection}{\numberline {3.1.2}Textnormalisierung}{21}{subsection.58}%
\contentsline {subsection}{\numberline {3.1.3}Tokenisierung}{23}{subsection.60}%
\contentsline {section}{\numberline {3.2}Word Embeddings}{24}{section.62}%
\contentsline {subsection}{\numberline {3.2.1}One-Hot-Encoding}{25}{subsection.63}%
\contentsline {subsection}{\numberline {3.2.2}Bag-of-Words}{25}{subsection.66}%
\contentsline {subsection}{\numberline {3.2.3}Skip-Gram-Model}{26}{subsection.69}%
\contentsline {subsection}{\numberline {3.2.4}Word2Vec}{27}{subsection.70}%
\contentsline {subsection}{\numberline {3.2.5}Byte-Pair-Encoding}{28}{subsection.72}%
\contentsline {subsection}{\numberline {3.2.6}GloVe}{29}{subsection.74}%
\contentsline {section}{\numberline {3.3}Deep Language Representations}{30}{section.76}%
\contentsline {subsection}{\numberline {3.3.1}ELMo}{30}{subsection.77}%
\contentsline {subsection}{\numberline {3.3.2}GPT}{31}{subsection.79}%
\contentsline {subsection}{\numberline {3.3.3}BERT}{32}{subsection.81}%
\contentsline {chapter}{\numberline {4}Datengrundlage}{35}{chapter.84}%
\contentsline {chapter}{\numberline {5}Abstraktiver Ansatz}{37}{chapter.85}%
\contentsline {section}{\numberline {5.1}Architektur}{38}{section.86}%
\contentsline {section}{\numberline {5.2}Training}{40}{section.87}%
\contentsline {section}{\numberline {5.3}Evaluation}{41}{section.88}%
\contentsline {chapter}{\numberline {6}Sprachtechnische Adaption}{43}{chapter.89}%
\contentsline {section}{\numberline {6.1}Konzeption}{43}{section.90}%
\contentsline {section}{\numberline {6.2}Training}{43}{section.91}%
\contentsline {section}{\numberline {6.3}Evaluation}{43}{section.92}%
\contentsline {chapter}{\numberline {7}Zusammenfassung}{44}{chapter.93}%
\contentsline {chapter}{\numberline {8}Diskussion und Ausblick}{45}{chapter.94}%
\contentsline {chapter}{Literaturverzeichnis}{50}{chapter.94}%
\contentsline {chapter}{Thesen}{53}{chapter*.96}%
\contentsline {chapter}{Selbstständigkeitserklärung}{54}{chapter*.97}%
\contentsline {chapter}{\numberline {A}Erster Anhang}{55}{appendix.98}%
\contentsline {chapter}{\numberline {B}Zweiter Anhang}{56}{appendix.99}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
