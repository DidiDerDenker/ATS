\babel@toc {ngerman}{}
\contentsline {chapter}{Inhaltsverzeichnis}{II}{chapter*.3}%
\contentsline {chapter}{Abbildungsverzeichnis}{III}{chapter*.4}%
\contentsline {chapter}{Tabellenverzeichnis}{IV}{chapter*.5}%
\contentsline {chapter}{Abkürzungsverzeichnis}{V}{chapter*.6}%
\contentsline {chapter}{Quellcodeverzeichnis}{VII}{chapter*.7}%
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.8}%
\contentsline {section}{\numberline {1.1}Zielsetzung}{2}{section.12}%
\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{3}{section.14}%
\contentsline {section}{\numberline {1.3}Forschungsstand \& Referenzen}{3}{section.16}%
\contentsline {chapter}{\numberline {2}Deep Learning}{5}{chapter.23}%
\contentsline {section}{\numberline {2.1}Neuronale Netze}{5}{section.25}%
\contentsline {section}{\numberline {2.2}Architekturen}{8}{section.31}%
\contentsline {subsection}{\numberline {2.2.1}Recurrent Neural Networks}{8}{subsection.32}%
\contentsline {subsection}{\numberline {2.2.2}Encoder-Decoder-Networks}{11}{subsection.36}%
\contentsline {subsection}{\numberline {2.2.3}Attention in Neural Networks}{12}{subsection.38}%
\contentsline {subsection}{\numberline {2.2.4}Transformer Networks}{15}{subsection.42}%
\contentsline {section}{\numberline {2.3}Hyperparameter}{17}{section.44}%
\contentsline {section}{\numberline {2.4}Transfer Learning}{19}{section.49}%
\contentsline {chapter}{\numberline {3}Natural Language Processing}{21}{chapter.51}%
\contentsline {section}{\numberline {3.1}Vorverarbeitung}{22}{section.54}%
\contentsline {subsection}{\numberline {3.1.1}Textbereinigung}{22}{subsection.55}%
\contentsline {subsection}{\numberline {3.1.2}Textnormalisierung}{22}{subsection.56}%
\contentsline {subsection}{\numberline {3.1.3}Tokenisierung}{24}{subsection.58}%
\contentsline {section}{\numberline {3.2}Word Embeddings}{25}{section.60}%
\contentsline {subsection}{\numberline {3.2.1}One-Hot-Encoding}{26}{subsection.61}%
\contentsline {subsection}{\numberline {3.2.2}Bag-of-Words}{26}{subsection.64}%
\contentsline {subsection}{\numberline {3.2.3}Skip-Gram-Model}{27}{subsection.67}%
\contentsline {subsection}{\numberline {3.2.4}Word2Vec}{28}{subsection.68}%
\contentsline {subsection}{\numberline {3.2.5}Byte-Pair-Encoding}{29}{subsection.71}%
\contentsline {subsection}{\numberline {3.2.6}GloVe}{30}{subsection.73}%
\contentsline {section}{\numberline {3.3}Deep Language Representations}{31}{section.75}%
\contentsline {subsection}{\numberline {3.3.1}ELMo}{31}{subsection.76}%
\contentsline {subsection}{\numberline {3.3.2}GPT}{32}{subsection.78}%
\contentsline {subsection}{\numberline {3.3.3}BERT}{33}{subsection.80}%
\contentsline {chapter}{\numberline {4}Datengrundlage}{36}{chapter.84}%
\contentsline {chapter}{\numberline {5}Abstraktiver Ansatz}{38}{chapter.85}%
\contentsline {section}{\numberline {5.1}Metriken}{38}{section.86}%
\contentsline {subsection}{\numberline {5.1.1}ROUGE}{38}{subsection.91}%
\contentsline {subsection}{\numberline {5.1.2}BLEU}{40}{subsection.93}%
\contentsline {section}{\numberline {5.2}Architektur}{40}{section.94}%
\contentsline {section}{\numberline {5.3}Experimente}{43}{section.96}%
\contentsline {chapter}{\numberline {6}Sprachtechnische Adaption}{46}{chapter.99}%
\contentsline {section}{\numberline {6.1}Architektur}{46}{section.100}%
\contentsline {section}{\numberline {6.2}Experimente}{46}{section.101}%
\contentsline {chapter}{\numberline {7}Zusammenfassung}{48}{chapter.102}%
\contentsline {chapter}{\numberline {8}Diskussion und Ausblick}{49}{chapter.103}%
\contentsline {chapter}{Literaturverzeichnis}{50}{chapter.103}%
\contentsline {chapter}{Thesen}{54}{chapter*.105}%
\contentsline {chapter}{Selbstständigkeitserklärung}{55}{chapter*.106}%
\contentsline {chapter}{Quellcode}{56}{chapter*.107}%
\contentsline {chapter}{\numberline {A}Englischer Text}{66}{appendix.544}%
\contentsline {chapter}{\numberline {B}Deutscher Text}{67}{appendix.545}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
