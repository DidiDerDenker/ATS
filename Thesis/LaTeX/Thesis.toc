\babel@toc {ngerman}{}
\contentsline {chapter}{Inhaltsverzeichnis}{II}{chapter*.3}%
\contentsline {chapter}{Abbildungsverzeichnis}{III}{chapter*.4}%
\contentsline {chapter}{Tabellenverzeichnis}{IV}{chapter*.5}%
\contentsline {chapter}{Abkürzungsverzeichnis}{V}{chapter*.6}%
\contentsline {chapter}{Quellcodeverzeichnis}{VII}{chapter*.7}%
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.8}%
\contentsline {section}{\numberline {1.1}Zielsetzung}{2}{section.12}%
\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{3}{section.14}%
\contentsline {section}{\numberline {1.3}Forschungsstand \& Referenzen}{3}{section.16}%
\contentsline {chapter}{\numberline {2}Deep Learning}{5}{chapter.23}%
\contentsline {section}{\numberline {2.1}Neuronale Netze}{5}{section.25}%
\contentsline {section}{\numberline {2.2}Architekturen}{7}{section.30}%
\contentsline {subsection}{\numberline {2.2.1}Recurrent Neural Networks}{7}{subsection.31}%
\contentsline {subsection}{\numberline {2.2.2}Encoder-Decoder-Networks}{10}{subsection.35}%
\contentsline {subsection}{\numberline {2.2.3}Attention in Neural Networks}{12}{subsection.37}%
\contentsline {subsection}{\numberline {2.2.4}Transformer Networks}{14}{subsection.42}%
\contentsline {section}{\numberline {2.3}Hyperparameter}{16}{section.44}%
\contentsline {section}{\numberline {2.4}Transfer Learning}{18}{section.49}%
\contentsline {chapter}{\numberline {3}Natural Language Processing}{20}{chapter.51}%
\contentsline {section}{\numberline {3.1}Vorverarbeitung}{21}{section.54}%
\contentsline {subsection}{\numberline {3.1.1}Textbereinigung}{21}{subsection.55}%
\contentsline {subsection}{\numberline {3.1.2}Textnormalisierung}{21}{subsection.56}%
\contentsline {subsection}{\numberline {3.1.3}Tokenisierung}{23}{subsection.58}%
\contentsline {section}{\numberline {3.2}Word Embeddings}{24}{section.60}%
\contentsline {subsection}{\numberline {3.2.1}One-Hot-Encoding}{25}{subsection.61}%
\contentsline {subsection}{\numberline {3.2.2}Bag-of-Words}{25}{subsection.64}%
\contentsline {subsection}{\numberline {3.2.3}Skip-Gram-Model}{26}{subsection.67}%
\contentsline {subsection}{\numberline {3.2.4}Word2Vec}{27}{subsection.68}%
\contentsline {subsection}{\numberline {3.2.5}Byte-Pair-Encoding}{28}{subsection.71}%
\contentsline {subsection}{\numberline {3.2.6}GloVe}{29}{subsection.73}%
\contentsline {section}{\numberline {3.3}Deep Language Representations}{30}{section.75}%
\contentsline {subsection}{\numberline {3.3.1}ELMo}{30}{subsection.76}%
\contentsline {subsection}{\numberline {3.3.2}GPT}{31}{subsection.78}%
\contentsline {subsection}{\numberline {3.3.3}BERT}{32}{subsection.80}%
\contentsline {chapter}{\numberline {4}Datengrundlage}{35}{chapter.84}%
\contentsline {chapter}{\numberline {5}Abstraktiver Ansatz}{37}{chapter.85}%
\contentsline {section}{\numberline {5.1}Metriken}{37}{section.86}%
\contentsline {subsection}{\numberline {5.1.1}ROUGE}{37}{subsection.91}%
\contentsline {subsection}{\numberline {5.1.2}BLEU}{39}{subsection.93}%
\contentsline {section}{\numberline {5.2}Architektur}{39}{section.94}%
\contentsline {section}{\numberline {5.3}Training}{44}{section.96}%
\contentsline {section}{\numberline {5.4}Evaluation}{44}{section.97}%
\contentsline {chapter}{\numberline {6}Sprachtechnische Adaption}{46}{chapter.98}%
\contentsline {section}{\numberline {6.1}Konzeption}{46}{section.99}%
\contentsline {section}{\numberline {6.2}Training}{46}{section.100}%
\contentsline {section}{\numberline {6.3}Evaluation}{46}{section.101}%
\contentsline {chapter}{\numberline {7}Zusammenfassung}{47}{chapter.102}%
\contentsline {chapter}{\numberline {8}Diskussion und Ausblick}{48}{chapter.103}%
\contentsline {chapter}{Literaturverzeichnis}{50}{chapter.103}%
\contentsline {chapter}{Thesen}{54}{chapter*.105}%
\contentsline {chapter}{Selbstständigkeitserklärung}{55}{chapter*.106}%
\contentsline {chapter}{\numberline {A}Erster Anhang}{56}{appendix.107}%
\contentsline {chapter}{\numberline {B}Zweiter Anhang}{57}{appendix.108}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
