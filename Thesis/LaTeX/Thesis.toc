\babel@toc {ngerman}{}
\contentsline {chapter}{Inhaltsverzeichnis}{II}{chapter*.3}%
\contentsline {chapter}{Abbildungsverzeichnis}{III}{chapter*.4}%
\contentsline {chapter}{Tabellenverzeichnis}{IV}{chapter*.8}%
\contentsline {chapter}{Abkürzungsverzeichnis}{V}{chapter*.9}%
\contentsline {chapter}{Quellcodeverzeichnis}{VI}{chapter*.10}%
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.11}%
\contentsline {section}{\numberline {1.1}Zielsetzung}{2}{section.15}%
\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{3}{section.17}%
\contentsline {section}{\numberline {1.3}Forschungsstand \& Referenzen}{3}{section.19}%
\contentsline {chapter}{\numberline {2}Deep Learning}{5}{chapter.24}%
\contentsline {section}{\numberline {2.1}Neuronale Netze}{5}{section.26}%
\contentsline {section}{\numberline {2.2}Architekturen}{7}{section.31}%
\contentsline {subsection}{\numberline {2.2.1}Recurrent Neural Networks}{7}{subsection.32}%
\contentsline {subsection}{\numberline {2.2.2}Encoder-Decoder-Networks}{10}{subsection.36}%
\contentsline {subsection}{\numberline {2.2.3}Attention in Neural Networks}{12}{subsection.38}%
\contentsline {subsection}{\numberline {2.2.4}Transformer Networks}{14}{subsection.43}%
\contentsline {section}{\numberline {2.3}Hyperparameter}{16}{section.45}%
\contentsline {section}{\numberline {2.4}Transfer Learning}{18}{section.50}%
\contentsline {chapter}{\numberline {3}Natural Language Processing}{20}{chapter.52}%
\contentsline {section}{\numberline {3.1}Vorverarbeitung}{21}{section.55}%
\contentsline {subsection}{\numberline {3.1.1}Textbereinigung}{21}{subsection.56}%
\contentsline {subsection}{\numberline {3.1.2}Textnormalisierung}{21}{subsection.57}%
\contentsline {subsection}{\numberline {3.1.3}Tokenisierung}{23}{subsection.59}%
\contentsline {section}{\numberline {3.2}Word Embeddings}{24}{section.61}%
\contentsline {subsection}{\numberline {3.2.1}One-Hot-Encoding}{25}{subsection.62}%
\contentsline {subsection}{\numberline {3.2.2}Bag-of-Words}{25}{subsection.65}%
\contentsline {subsection}{\numberline {3.2.3}Skip-Gram-Model}{26}{subsection.68}%
\contentsline {subsection}{\numberline {3.2.4}Word2Vec}{27}{subsection.69}%
\contentsline {subsection}{\numberline {3.2.5}Byte-Pair-Encoding}{27}{subsection.71}%
\contentsline {subsection}{\numberline {3.2.6}GloVe}{28}{subsection.73}%
\contentsline {section}{\numberline {3.3}Deep Language Representations}{29}{section.75}%
\contentsline {subsection}{\numberline {3.3.1}ELMo}{29}{subsection.76}%
\contentsline {subsection}{\numberline {3.3.2}GPT}{30}{subsection.78}%
\contentsline {subsection}{\numberline {3.3.3}BERT}{30}{subsection.79}%
\contentsline {chapter}{\numberline {4}Datengrundlage}{34}{chapter.83}%
\contentsline {chapter}{\numberline {5}Abstraktiver Ansatz}{36}{chapter.84}%
\contentsline {section}{\numberline {5.1}Architektur}{37}{section.85}%
\contentsline {section}{\numberline {5.2}Training}{39}{section.86}%
\contentsline {section}{\numberline {5.3}Evaluation}{39}{section.87}%
\contentsline {chapter}{\numberline {6}Sprachtechnische Adaption}{42}{chapter.88}%
\contentsline {section}{\numberline {6.1}Konzeption}{42}{section.89}%
\contentsline {section}{\numberline {6.2}Training}{42}{section.90}%
\contentsline {section}{\numberline {6.3}Evaluation}{42}{section.91}%
\contentsline {chapter}{\numberline {7}Zusammenfassung}{43}{chapter.92}%
\contentsline {chapter}{\numberline {8}Diskussion und Ausblick}{44}{chapter.93}%
\contentsline {chapter}{Literaturverzeichnis}{50}{chapter.93}%
\contentsline {chapter}{Thesen}{53}{chapter*.95}%
\contentsline {chapter}{Selbstständigkeitserklärung}{54}{chapter*.96}%
\contentsline {chapter}{\numberline {A}Erster Anhang}{55}{appendix.97}%
\contentsline {chapter}{\numberline {B}Zweiter Anhang}{56}{appendix.98}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
