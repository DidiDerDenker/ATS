\addcontentsline{toc}{chapter}{Literaturverzeichnis}
\setcounter{page}{50}

\begin{thebibliography}{50}
\thispagestyle{fancy}

% UNUSED
\bibitem[Backhaus et al., 2015]{BAC15}
Backhaus, Klaus \& Erichson, Bernd \& Plinke, Wulff \& Weiber, Rolf: Multivariate Analysemethoden, Verlag Springer Gabler, Berlin, Deutschland, 2015.

% UNUSED
\bibitem[Bird et al., 2009]{BIR09}
Bird, Steven \& Klein, Ewan \& Loper, Edward: Natural Language Processing with Python, Verlag O'Reilly, Sebastopol, Vereinigte Staaten, 2009.

\bibitem[Gambhir et al., 2016]{GAM16}
Gambhir, Mahak \& Gupta, Vishal: Recent Automatic Text Summarization Techniques, Seite 3-5, University of Panjab in Chandigargh, 2016.

\bibitem[Goncalves, 2020]{GON20}
Goncalves, Luis: Automatic Text Summarization with Machine Learning, in: https://medium.com/luisfredgs/automatic-text-summarization-with-machine-learning-an-overview-68ded5717a25, Aufruf am 01.01.2021.

% UNUSED
\bibitem[Kiani, 2017]{KIA17}
Kiani, Farzad: Automatic Text Summarization, University of Arel in Istanbul, 2017.

% UNUSED
\bibitem[Kriesel, 2005]{KRI05}
Kriesel, David: Ein kleiner Überblick über neuronale Netze, in: \url{http://www.dkriesel.com/science/neural_networks}, Aufruf am 01.01.2021.

% UNUSED
\bibitem[Nitsche, 2019]{NIT19}
Nitsche, Matthias: Towards German Abstractive Text Summarization using Deep Learning, HAW Hamburg, 2019.

% UNUSED
\bibitem[Paulus et al., 2017]{PAU17}
Paulus, Romain \& Xiong, Caiming \& Socher, Richard: A Deep Reinforced Model for Abstractive Summarization, in: \url{https://arxiv.org/pdf/1705.04304v3.pdf}, Aufruf am 01.01.2021.

% UNUSED
\bibitem[Rashid, 2017]{RAS17}
Rashid, Tariq: Neuronale Netze selbst programmieren, Verlag O'Reilly, Sebastopol, Vereinigte Staaten, 2017.

% UNUSED
\bibitem[Raschka et al., 2019]{RAS19}
Raschka, Sebastian \& Mirjalili, Vahid: Machine Learning and Deep Learning with Python, Verlag Packt, Birmingham, Vereinigtes Königreich, 2019.

% UNUSED
\bibitem[Rothe et al., 2020]{ROT20}
Rothe, Sascha \& Narayan, Shashi \& Severyn, Aliaksei: Leveraging Pre-Trained Checkpoints for Sequence Generation Tasks, Google Research, 2020.

% UNSUED
\bibitem[Yang et al., 2019]{YAN19}
Yang, Liu \& Lapata, Mirella: Text Summarization with Pretrained Encoders, Institute for Language, Cognition and Computation in Edinburgh, 2019.

% UNUSED
\bibitem[Zhang et al., 2020]{ZHA20}
Zhang, Aston \& Lipton, Zachary \& Li, Mu \& Smola, Alexander: Dive into Deep Learning, in: \url{https://d2l.ai/}, Aufruf am 01.01.2021.

\end{thebibliography}
