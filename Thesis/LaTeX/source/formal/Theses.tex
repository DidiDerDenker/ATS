\chapter*{Thesen}
\thispagestyle{empty}

\noindent
Die automatische Zusammenfassung von Texten lässt sich mithilfe eines Sequence-to-Sequence-Transformer-Modells, welches über einen vortrainierten Encoder und Decoder verfügt, SOTA-konform realisieren, insbesondere unter Nutzung von BERT und BART.\\
\newline

\noindent
Die Adaption auf die deutsche Sprache bedarf nicht zwingend einer architektonischen Anpassung, sondern einem Austausch der Textdaten in der entsprechenden Zielsprache, um Zusammenfassungen auf SOTA-Niveau zu generieren.\\
\newline

\noindent
Die Qualität der sprachtechnischen Adaption ist sehr stark von der Qualität der vortrainierten Modelle sowie dem Umfang und der Beschaffenheit der zugrundeliegenden Textdaten abhängig.
