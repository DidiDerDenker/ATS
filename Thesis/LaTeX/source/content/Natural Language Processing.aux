\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{BIR09}
\citation{BIR09}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Natural Language Processing}{20}{chapter.52}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{chap:Natural Language Processing}{{3}{20}{Natural Language Processing}{chapter.52}{}}
\acronymused{NLP}
\acronymused{NLP}
\AC@undonewlabel{acro:NLU}
\newlabel{acro:NLU}{{3}{20}{Natural Language Processing}{section*.53}{}}
\acronymused{NLU}
\AC@undonewlabel{acro:NLG}
\newlabel{acro:NLG}{{3}{20}{Natural Language Processing}{section*.54}{}}
\acronymused{NLG}
\acronymused{ATS}
\acronymused{NLP}
\acronymused{ATS}
\acronymused{NLP}
\citation{BIR09}
\citation{BIR09}
\citation{GAM16}
\citation{BIR09}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Vorverarbeitung}{21}{section.55}\protected@file@percent }
\acronymused{NLP}
\acronymused{NLP}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Textbereinigung}{21}{subsection.56}\protected@file@percent }
\acronymused{NLP}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Textnormalisierung}{21}{subsection.57}\protected@file@percent }
\citation{BIR09}
\citation{NLT20}
\citation{SPA21}
\citation{BIR09}
\AC@undonewlabel{acro:NLTK}
\newlabel{acro:NLTK}{{3.1.2}{22}{Textnormalisierung}{section*.58}{}}
\acronymused{NLTK}
\acronymused{NLP}
\acronymused{NLP}
\citation{MAN08}
\citation{BIR09}
\citation{ZHA20}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}Tokenisierung}{23}{subsection.59}\protected@file@percent }
\acronymused{NLP}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Tokenisierung eines beispielhaften Satzes.\relax }}{23}{figure.caption.60}\protected@file@percent }
\newlabel{pic:Tokenization}{{3.1}{23}{Tokenisierung eines beispielhaften Satzes.\relax }{figure.caption.60}{}}
\citation{BIR09}
\citation{KAR18}
\citation{BRO19}
\citation{NIT19}
\acronymused{NLTK}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Word Embeddings}{24}{section.61}\protected@file@percent }
\acronymused{NLP}
\acronymused{NLP}
\acronymused{NLP}
\acronymused{ATS}
\citation{KAR18}
\citation{KAR18}
\citation{RAS19}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}One-Hot-Encoding}{25}{subsection.62}\protected@file@percent }
\AC@undonewlabel{acro:OHE}
\newlabel{acro:OHE}{{3.2.1}{25}{One-Hot-Encoding}{section*.63}{}}
\acronymused{OHE}
\acronymused{OHE}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces One-Hot-Encoding mit zwei beispielhaften S채tzen.\relax }}{25}{figure.caption.64}\protected@file@percent }
\newlabel{pic:OneHotEncoding}{{3.2}{25}{One-Hot-Encoding mit zwei beispielhaften S채tzen.\relax }{figure.caption.64}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Bag-of-Words}{25}{subsection.65}\protected@file@percent }
\AC@undonewlabel{acro:BOW}
\newlabel{acro:BOW}{{3.2.2}{25}{Bag-of-Words}{section*.66}{}}
\acronymused{BOW}
\acronymused{BOW}
\citation{BRO19}
\citation{HUI20}
\citation{HUI20}
\citation{HUI20}
\citation{ZHA20}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Bag-of-Words mit einem beispielhaften Wortschatz \cite  {HUI20}.\relax }}{26}{table.caption.67}\protected@file@percent }
\newlabel{table:BagOfWords}{{3.1}{26}{Bag-of-Words mit einem beispielhaften Wortschatz \cite {HUI20}.\relax }{table.caption.67}{}}
\acronymused{ATS}
\acronymused{NLP}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Skip-Gram-Model}{26}{subsection.68}\protected@file@percent }
\citation{ZHA20}
\citation{ZHA20}
\citation{KAR18}
\citation{NIT19}
\citation{NIT19}
\acronymused{ATS}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Word2Vec}{27}{subsection.69}\protected@file@percent }
\AC@undonewlabel{acro:W2V}
\newlabel{acro:W2V}{{3.2.4}{27}{Word2Vec}{section*.70}{}}
\acronymused{W2V}
\acronymused{BOW}
\acronymused{OHE}
\acronymused{BOW}
\acronymused{BOW}
\acronymused{W2V}
\acronymused{ATS}
\acronymused{W2V}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Byte-Pair-Encoding}{27}{subsection.71}\protected@file@percent }
\AC@undonewlabel{acro:BPE}
\newlabel{acro:BPE}{{3.2.5}{27}{Byte-Pair-Encoding}{section*.72}{}}
\acronymused{BPE}
\citation{PEN14}
\citation{PEN14}
\citation{NIT19}
\citation{PEN14}
\acronymused{BPE}
\acronymused{BPE}
\acronymused{ATS}
\acronymused{W2V}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}GloVe}{28}{subsection.73}\protected@file@percent }
\AC@undonewlabel{acro:GloVe}
\newlabel{acro:GloVe}{{3.2.6}{28}{GloVe}{section*.74}{}}
\acronymused{GloVe}
\acronymused{GloVe}
\acronymused{W2V}
\acronymused{GloVe}
\acronymused{TL}
\acronymused{NLP}
\acronymused{ATS}
\acronymused{GloVe}
\acronymused{NLP}
\citation{NIT19}
\citation{DEV19}
\citation{DEV19}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Deep Language Representations}{29}{section.75}\protected@file@percent }
\acronymused{NLP}
\acronymused{ATS}
\acronymused{NLU}
\acronymused{NLG}
\acronymused{TL}
\acronymused{NLP}
\acronymused{ATS}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}BERT}{29}{subsection.76}\protected@file@percent }
\acronymused{BERT}
\acronymused{BERT}
\acronymused{NLP}
\acronymused{BERT}
\acronymused{BERT}
\acronymused{BERT}
\acronymused{BERT}
\citation{DEV19}
\citation{DEV19}
\citation{DEV19}
\citation{DEV19}
\citation{DEV19}
\citation{DEV19}
\acronymused{BERT}
\acronymused{BERT}
\acronymused{MLM}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Architektur von BERT mit \ac {MLM} \cite  [S.~3]{DEV19}.\relax }}{30}{figure.caption.77}\protected@file@percent }
\acronymused{MLM}
\newlabel{pic:BertEncoder}{{3.3}{30}{Architektur von BERT mit \ac {MLM} \cite [S.~3]{DEV19}.\relax }{figure.caption.77}{}}
\acronymused{BERT}
\citation{DEV19}
\citation{ROT20}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Repr채sentation von Textdaten mithilfe von BERT \cite  [S.~3]{DEV19}.\relax }}{31}{figure.caption.78}\protected@file@percent }
\newlabel{pic:InputRepresentation}{{3.4}{31}{Repr채sentation von Textdaten mithilfe von BERT \cite [S.~3]{DEV19}.\relax }{figure.caption.78}{}}
\acronymused{BERT}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}ELMo}{31}{subsection.79}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}GPT}{31}{subsection.80}\protected@file@percent }
\citation{NIT19}
\@setckpt{source/content/Natural Language Processing}{
\setcounter{page}{34}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{3}
\setcounter{subsection}{3}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{1}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{float@type}{8}
\setcounter{lstnumber}{1}
\setcounter{AM@survey}{0}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{header@val}{0}
\setcounter{max@header@val}{0}
\setcounter{parentequation}{0}
\setcounter{BAenumi}{0}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
