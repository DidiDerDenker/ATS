\chapter{Experimente}
\thispagestyle{fancy}
\label{chap:Experimente}

\noindent
Unter Kenntnis der Grundlagen des \ac{DL}, des \ac{NLP} und der \ac{ATS} wird nun ein Ablauf von Experimenten konzipiert, welcher verschiedene \ac{TF2TF} definiert und ein entsprechendes Fine-Tuning vorsieht. Zuvor wird die entsprechende Entwicklungsumgebung offengelegt.


\section{Entwicklungsumgebung}
\noindent
Die Entwicklung und die Durchführung aller Experimente geschieht in Python. Dies ist eine Programmiersprache, welche sich insbesondere für \ac{ML}- und \ac{DL}-Zwecke eignet. Dabei werden Trainingsprozesse durch \ac{CUDA} unterstützt, wenn entsprechende Voraussetzungen erfüllt sind. \ac{CUDA} ist eine von NVIDIA entwickelte Technik, welche es ermöglicht, bestimmte Operationen mithilfe der GPU zu beschleunigen \cite{NVI21}. Zudem ist es in dieser Umgebung möglich, vortrainierte Modelle wie \ac{BERT}, {XLM-R} und \ac{BART} zu laden und Architekturen weitergehend gemäß der bereits bekannten Konfiguration zu präparieren, darunter beispielsweise die beschriebene Encoder-Decoder-Architektur. Dies wird durch die Bibliothek PyTorch und das US-Unternehmen HuggingFace, welches den Code als Open Source bereitstellt, ermöglicht. HuggingFace stellt zudem verschiedene Klassen zum Trainieren von Sequence-to-Sequence-Modellen bereit \cite{HUG21}. Darüber hinaus erfolgen alle Experimente dieser Arbeit über einen legitimierten Zugang auf dem Hochleitungsrechner der TU Dresden, namentlich Taurus, um das Potenzial der verfügbaren Umgebung mithilfe einer leistungsstarken GPU (NVIDIA A100) vollends auszuschöpfen \cite{ZIH21}. Der Quellcode ist dem Anhang zu entnehmen.
\newpage


\section{Reproduktion auf englischen Daten}
\noindent
Zunächst erfolgt die Reproduktion des \ac{SOTA} auf Grundlage der konzipierten Architektur, um eine Baseline zu setzen, an welcher sich in nachfolgenden Experimenten verglichen und gemessen werden kann. Daher ist es unabdingbar, je ein erstes \ac{TF2TF} unter Nutzung von \ac{BERT} und {XLM-R} als Encoder und Decoder auf den englischsprachigen Daten ($K_{eng}$) zu trainieren und zu evaluieren. Dies folgt der beschriebenen Architektur und der entsprechenden Konfiguration ohne Kompromisse.


\section{Adaption auf deutschen Daten}
\noindent
Anschließend wird die Adaption auf die deutsche Sprache erprobt. Dies erfolgt bekanntermaßen über den Austausch der Textdaten in die Zielsprache, hier Deutsch. Dafür werden zwei weitere \ac{TF2TF} unter Nutzung der oben genannten \ac{DLR} jeweils auf Basis aller deutschsprachigen Daten ($K_{wik} \cup K_{nws} \cup K_{mls}$) trainiert und evaluiert.


\section{Adaption auf multilingualen Daten}
\noindent
Basierend auf der Annahme, multilinguale \ac{DLR} würden von verborgenen Strukturen anderer Sprachen profitieren, werden erneut zwei \ac{TF2TF} unter Nutzung beider \ac{DLR} jeweils auf einem Mix aus allen englisch- und deutschsprachigen Daten ($K_{eng} \cup K_{wik} \cup K_{nws} \cup K_{mls}$) trainiert und auf Basis einer deutschsprachigen Evaluation mit den bisherigen Fortschritten verglichen. \ac{BART} wird nun ebenfalls herangezogen, allerdings nicht selbst trainiert, sondern fortan nur als multilingual weitertrainiertes Modell von HuggingFace bezogen.
