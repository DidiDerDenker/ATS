\chapter{Sprachtechnische Adaption}
\thispagestyle{fancy}
\label{chap:Sprachtechnische Adaption}

\noindent
Unter Kenntnis der Architektur des abstraktiven Ansatzes und der Baseline des englischsprachigen Modells wird nun ergründet, wie eine Adaption auf die deutsche Sprache erfolgen kann. Dies wird mithilfe verschiedener Experimente erprobt, welche sich weiterhin auf die bekannten Metriken stützen.\\


\section{Architektur}
\noindent
+ Beschreiben, warum die Architektur sich für die Multilingualität eignet
+ Anpassungen dokumentieren, anderweitig parametrisieren
+ Auswahl von BERT damit begründen, dass Multilingualität gegeben ist, gut erforscht, Alternativen nicht, obwohl sie teilweise Verbesserungen versprechen, aber Alternativen nennen, teilweise keine Unterstützung der Multilingualität, da zunächst auf englischen Daten erprobt und bewiesen sein muss
+ \url{https://towardsdatascience.com/deep-generative-models-25ab2821afd3}: Deep Generative Models: BERT: Verteilung von Daten unüberwacht lernen, d.h. ungelabelte Daten, Berechnung bedingter Wahrscheinlichkeiten\\


\section{Experimente}
\noindent
+ Trainings und Tests ausführen
+ Korpora austauschen o.ä.\\
