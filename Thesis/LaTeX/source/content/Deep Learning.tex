\chapter{Deep Learning}
\thispagestyle{fancy}
\label{chap:Deep Learning}

Notizen:
\begin{itemize}
	\item Deep Learning definieren
	\item Machine Learning erwähnen
	\item Siehe Abstract im Exposé
\end{itemize}


\section{Neuronale Netze}
Notizen:
\begin{itemize}
	\item Neuronale Netze definieren
	\item Historie beschreiben
	\item Funktionsweise und ausgewählte Komponenten beschreiben
\end{itemize}


\section{Reinforcement Learning}
Notizen:
\begin{itemize}
	\item Reinforcement Learning definieren
	\item Bisherige Errungenschaften und Eigenschaften erwähnen
	\item Funktionsweise und ausgewählte Komponenten ggf. in Unterkapiteln beschreiben
\end{itemize}


\section{Architekturen}
Notizen:
\begin{itemize}
	\item Existenz und Notwendigkeit verschiedener Architekturen ankündigen
	\item Später benötigte Architekturen hier beschreiben
	\item Diversität der existierenden Architekturen (wie im Forschungsstand bereits erwähnt) hervorheben
	\item "Reinforcement Learning comes to the rescue" aus \url{https://towardsdatascience.com/deep-learning-models-for-automatic-summarization-4c2b89f2a9ea} einbinden
\end{itemize}


\subsection{MLP}
Notizen:


\subsection{RNN}
Notizen:


\subsection{LSTM}
Notizen:


\section{Hyperparameter}
Notizen:
\begin{itemize}
	\item Hyperparameter vorstellen
	\item Notwendigkeit und Einfluss von Hyperparametern beschreiben
\end{itemize}


\section{Evaluation}
Notizen:
\begin{itemize}
	\item Es muss eine Metrik existieren, mit der man die Genauigkeit bzw. Qualität der Zusammenfassung messen kann, d.h. man möchte die Texte nicht mit menschlich generierten Zusammenfassungen vergleichen, sondern automatisiert lernen, ggf. sollte man auch Grammatik und Inhalt separat prüfen
	\item For a given document there is no summary which is objectively the best. As a general rule, many of them that would be judged equally good by a human. It is hard to define precisely what a good summary is and what score we should use for its evaluation. Good training data has long been scarce and expensive to collect. Human evaluation of a summary is subjective and involves judgments like style, coherence, completeness and readability. Unfortunately no score is currently known which is both easy to compute and faithful to human judgment. The ROUGE score [6] is the best we have but it has obvious shortcomings as we shall see. ROUGE simply counts the number of words, or n-grams, that are common to the summary produced by a machine and a reference summary written by a human. \url{https://towardsdatascience.com/deep-learning-models-for-automatic-summarization-4c2b89f2a9ea}
	\item Bei der Anwendung einer Architektur, in der das Modell durch Reinforcement Learning trainiert wird, braucht man keine massenhaft menschlich generierten Referenztexte, sondern eine wohlbedachte Kostenfunktion, der ein entsprechender Aufwand entgegen gebracht werden muss
\end{itemize}
